{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9f9ff929df5e032d99e77a81bb129c0081de7ad"
   },
   "source": [
    "<div>\n",
    "<h3>Suggestion Mining</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os, gc, time, warnings\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "import scipy.stats as ss\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "import matplotlib.pyplot as plt, matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud ,STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "import string, re, nltk, collections\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "413525163c3d8d0870200e1da91596e8578f7860"
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "\n",
    "train = pd.read_csv(\"V1.4_Training.csv\", encoding = 'latin-1')\n",
    "dev = pd.read_csv(\"SubtaskA_Trial_Test_Labeled.csv\", encoding = 'latin-1')\n",
    "test = pd.read_csv(\"SubtaskA_EvaluationData.csv\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccf76a409b4e7437d3cd824e31636a2e3c22367e"
   },
   "source": [
    "<div><h3 id = \"eda\"> Exploratory Data Analysis </h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f74e2050c74454911343176872cd0092cb2702de"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "14036485a842bbdc85443e4fe4d9bbcabb11960a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663_4</td>\n",
       "      <td>\"Note: in your .csproj file, there is a Suppor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>664_1</td>\n",
       "      <td>\"Wich means the new version not fully replaced...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664_2</td>\n",
       "      <td>\"Some of my users will still receive the old x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664_3</td>\n",
       "      <td>\"The store randomly gives the old xap or the n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>664_4</td>\n",
       "      <td>\"My app has a WP7 version and a WP8 version XA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>664_5</td>\n",
       "      <td>\"The wp7 xap works only on WP7 and the wp8 xap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>665_1</td>\n",
       "      <td>\"Sometimes the Store gives the wrong wp7 xap v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>665_2</td>\n",
       "      <td>\"It should be an option to remove the \"ru\" lan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>665_3</td>\n",
       "      <td>\"Currently if you ever mistakenly selected a \"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>665_5</td>\n",
       "      <td>\"): the store will randomly deliver the old/wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           sentence  label\n",
       "0  663_4  \"Note: in your .csproj file, there is a Suppor...      0\n",
       "1  664_1  \"Wich means the new version not fully replaced...      0\n",
       "2  664_2  \"Some of my users will still receive the old x...      0\n",
       "3  664_3  \"The store randomly gives the old xap or the n...      0\n",
       "4  664_4  \"My app has a WP7 version and a WP8 version XA...      0\n",
       "5  664_5  \"The wp7 xap works only on WP7 and the wp8 xap...      0\n",
       "6  665_1  \"Sometimes the Store gives the wrong wp7 xap v...      0\n",
       "7  665_2  \"It should be an option to remove the \"ru\" lan...      1\n",
       "8  665_3  \"Currently if you ever mistakenly selected a \"...      0\n",
       "9  665_5  \"): the store will randomly deliver the old/wr...      0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = train.rename(columns={'663_3': 'id','\"Please enable removing language code from the Dev Center \"language history\" For example if you ever selected \"ru\" and \"ru-ru\" laguages and you published this xap to the Store then it causes Tile localization to show the en-us(default) tile localization which is bad.\"': 'sentence','1': 'label'})\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "e1e6686c29472e0142885d37b12a122c50c1f615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8499 entries, 0 to 8498\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        8499 non-null   object\n",
      " 1   sentence  8499 non-null   object\n",
      " 2   label     8499 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 199.3+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data...\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "5c942b44b014dac379c6b51735a22328af7e74e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences : 8499\n",
      "Total suggestions : 2084\n",
      "Total non_suggestions : 6415\n"
     ]
    }
   ],
   "source": [
    "# class-imbalance in training data\n",
    "\n",
    "suggestion_count = (train['label'].values == 1).astype(int).sum()\n",
    "non_suggestion_count = (train['label'].values == 0).astype(int).sum()\n",
    "print(\"Total sentences : \" + str(train.shape[0]))\n",
    "print(\"Total suggestions : \" + str(suggestion_count))\n",
    "print(\"Total non_suggestions : \" + str(non_suggestion_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85fbf28b3b29eca7689540ed20da20476471eda9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "9a494095fbd0f6e4b9b7fbbf176d9721707d5040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12830 entries, 0 to 12829\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        12830 non-null  object\n",
      " 1   sentence  12830 non-null  object\n",
      " 2   label     12830 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 300.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# oversampling to balance the training data\n",
    "\n",
    "suggestions = train[train['label'].values == 1]\n",
    "\n",
    "while suggestion_count < non_suggestion_count:\n",
    "    random_suggestion = suggestions.sample()\n",
    "    train = train.append(random_suggestion, ignore_index = True)\n",
    "    suggestion_count = suggestion_count + 1\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "5afc1b93676d3c90eaff1672d864f932a2cb2afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 592 entries, 0 to 591\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        592 non-null    object\n",
      " 1   sentence  592 non-null    object\n",
      " 2   label     592 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# exploring the development/validation data\n",
    "\n",
    "print(\"Development Set...\")\n",
    "dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_uuid": "5513e4881d7047721dd24d4b9984b646f9c67daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences : 592\n",
      "Total suggestions : 296\n",
      "Total non_suggestions : 296\n"
     ]
    }
   ],
   "source": [
    "# class-imbalance in development data\n",
    "\n",
    "suggestion_count = (dev['label'].values == 1).astype(int).sum()\n",
    "non_suggestion_count = (dev['label'].values == 0).astype(int).sum()\n",
    "print(\"Total sentences : \" + str(dev.shape[0]))\n",
    "print(\"Total suggestions : \" + str(suggestion_count))\n",
    "print(\"Total non_suggestions : \" + str(non_suggestion_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3587f7a8647810b5673a9498570e80ffcd8521d2"
   },
   "outputs": [],
   "source": [
    "# Aphost lookup dict\n",
    "\n",
    "APPO = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"i'd\" : \"I would\",\n",
    "    \"i'd\" : \"I had\",\n",
    "    \"i'll\" : \"I will\",\n",
    "    \"i'm\" : \"I am\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"i've\" : \"I have\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mightn't\" : \"might not\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"what'll\" : \"what will\",\n",
    "    \"what're\" : \"what are\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"what've\" : \"what have\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who'd\" : \"who would\",\n",
    "    \"who'll\" : \"who will\",\n",
    "    \"who're\" : \"who are\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"who've\" : \"who have\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'll\":\" will\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"tryin'\":\"trying\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f1b9d5bf4b3adb978a3c1f91c3ae5d1e6b4fc48c"
   },
   "outputs": [],
   "source": [
    "def clean(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('<.*>', '', sentence)\n",
    "    sentence = re.sub(\"\\\\n\", \"\", sentence)\n",
    "    sentence = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", sentence)\n",
    "    sentence = re.sub(\"\\[\\[.*\\]\", \"\", sentence)\n",
    "    sentence = re.sub(\"[\" + re.sub(\"\\.\",\"\",string.punctuation) + \"]\", \"\", sentence)\n",
    "    \n",
    "    words = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    words = [APPO[word] if word in APPO else word for word in words]\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    words = [lem.lemmatize(word, \"v\") for word in words]\n",
    "    words = [w for w in words if not w in eng_stopwords]\n",
    "    \n",
    "    clean_sent = \" \".join(words)\n",
    "    \n",
    "    return(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "8cfdf908dc00c55671c03a31cdc5157626131f0f"
   },
   "outputs": [],
   "source": [
    "# obtaining separate clean corpora for suggestion and non-suggestion classes\n",
    "\n",
    "suggestion_corpus = train[train['label'].values == 1].sentence\n",
    "suggestion_corpus = suggestion_corpus.append(dev[dev['label'].values == 1].sentence)\n",
    "#clean_suggestion_corpus = \"\"\n",
    "#for sentence in suggestion_corpus:\n",
    "   # clean_suggestion_corpus += clean(sentence)\n",
    "\n",
    "non_suggestion_corpus = train[train['label'].values == 0].sentence\n",
    "non_suggestion_corpus = non_suggestion_corpus.append(dev[dev['label'].values == 0].sentence)\n",
    "#clean_non_suggestion_corpus = \"\"\n",
    "#for sentence in non_suggestion_corpus:\n",
    "    #clean_non_suggestion_corpus += clean(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "bf44113d90119657b9638cb058af73e56d92884d"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-f9d9aae56a95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# top 20 bigrams in suggestion sentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msuggestion_bigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuggestion_corpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msuggestion_bigrams_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuggestion_bigrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msuggestion_bigrams_freq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# top 20 bigrams in suggestion sentences\n",
    "\n",
    "suggestion_bigrams = ngrams(suggestion_corpus.split(), 2)\n",
    "suggestion_bigrams_freq = collections.Counter(suggestion_bigrams)\n",
    "suggestion_bigrams_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "0fd64cdb36f80caa27efefd99dcf15bab550db81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 bigrams in non-suggestion sentences\n",
    "\n",
    "non_suggestion_bigrams = ngrams(non_suggestion_corpus.split(), 2)\n",
    "non_suggestion_bigrams_freq = collections.Counter(non_suggestion_bigrams)\n",
    "non_suggestion_bigrams_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "86c0d4e9c88251fbe79e233cf98f55fae29e8570"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(suggestions)\n",
    "del(subset)\n",
    "del(content)\n",
    "del(stopword)\n",
    "del(wc)\n",
    "del(suggestion_corpus)\n",
    "del(clean_suggestion_corpus)\n",
    "del(non_suggestion_corpus)\n",
    "del(clean_non_suggestion_corpus)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b8f8d3e0df86c751d5d5e9c503012b156aed9fb"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54df2e39d6c8a3ae8d893c37cdbf77297bf5e36a"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c80ddf190c5aa410b025d7914a316340af34d151"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b14bf77597d09ccbb3e77533fba7ff2c5a9d162"
   },
   "source": [
    "\n",
    "<h3 id=\"fe\"> Feature Engineering </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "cb411bd69aa55d40512ad4aff9c85e64cdf1036c"
   },
   "outputs": [],
   "source": [
    "# corpus containing all the sentences in train, development and test data\n",
    "\n",
    "corpus = (pd.concat([train.iloc[:, 0:2], dev.iloc[:, 0:2], test.iloc[:, 0:2]])).sentence\n",
    "clean_corpus = corpus.apply(lambda x : clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "72a05a6d63f95ace49dbf2aa21825984a1e2ce77"
   },
   "outputs": [],
   "source": [
    "# tf-idf vectors with bigram and trigram features\n",
    "\n",
    "btgram_tfv = TfidfVectorizer(strip_accents = 'unicode', analyzer = 'word', ngram_range = (2,3),\n",
    "            sublinear_tf = 1, stop_words = 'english')\n",
    "btgram_tfv.fit(clean_corpus)\n",
    "\n",
    "train_btgrams = btgram_tfv.transform(clean_corpus.iloc[:train.shape[0]])\n",
    "dev_btgrams = btgram_tfv.transform(clean_corpus.iloc[train.shape[0]:train.shape[0]+dev.shape[0]])\n",
    "test_btgrams = btgram_tfv.transform(clean_corpus.iloc[train.shape[0]+dev.shape[0]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d5a33f8e94b3c3892e6306f36501d4193ab8160"
   },
   "source": [
    "\n",
    "    <h3>Evaluation Metrics</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ff99047f9c7eb21140c61d8b165ab49d83f779ae"
   },
   "outputs": [],
   "source": [
    "# evaluation functions \n",
    "\n",
    "def lgb_f1_score(preds, train_data):\n",
    "    y_train = train_data.get_label()\n",
    "    preds = (preds >= 0.5).astype(int)\n",
    "    return 'f1_score', f1_score(y_train, preds), True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes for blending\n",
    "\n",
    "train_labels = pd.DataFrame()\n",
    "dev_labels = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1365e88e36cee5cb2e10f00c96bef273cd6cb5c"
   },
   "source": [
    "<div>\n",
    "    <h3 Statistical Models </h3>\n",
    "    <p> Logistic Regression and Support Vector Machine (SVM).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "fae85a6e31a97cf83e79591fa4baac3eab8f0a43"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train = hstack((train_unigrams, train_btgrams, train_charngrams)).tocsr()\n",
    "y_train = train['label'].values\n",
    "x_dev = hstack((dev_unigrams, dev_btgrams, dev_charngrams)).tocsr()\n",
    "y_dev = dev['label'].values\n",
    "x_test = hstack((test_unigrams, test_btgrams, test_charngrams)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "b5f6a7b24ef3a739607a7503c1e3e487e283bd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression...\n",
      "Precision score : 0.7489878542510121\n",
      "Recall score : 0.625\n",
      "F1 score : 0.6813996316758747\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classifier\n",
    "\n",
    "clf = LogisticRegression(C = 0.1, solver = 'liblinear')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "lr_dev_pred = clf.predict_proba(x_dev)[:, 1]\n",
    "lr_test_pred = clf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "train_labels['lr'] = (clf.predict_proba(x_train)[:, 1] >= 0.5).astype(int)\n",
    "dev_labels['lr'] = (clf.predict_proba(x_dev)[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "y_pred = (lr_dev_pred >= 0.5).astype(int)\n",
    "lr_precision = precision_score(y_dev, y_pred)\n",
    "lr_recall = recall_score(y_dev, y_pred)\n",
    "lr_f1 = f1_score(y_dev, y_pred)\n",
    "\n",
    "print(\"Logistic Regression...\")\n",
    "print(\"Precision score : \" + str(lr_precision))\n",
    "print(\"Recall score : \" + str(lr_recall))\n",
    "print(\"F1 score : \" + str(lr_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "01d4a4e807951ecb90fcebe8e70ea811a63fa1b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier...\n",
      "Precision score : 0.697508896797153\n",
      "Recall score : 0.6621621621621622\n",
      "F1 score : 0.6793760831889081\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier\n",
    "\n",
    "# reducing the number of features using Singular Value Decomposition\n",
    "svd = TruncatedSVD(n_components = 15)\n",
    "svd.fit(vstack((x_train, x_dev, x_test)).tocsr())\n",
    "x_train_svd = svd.transform(x_train)\n",
    "x_dev_svd = svd.transform(x_dev)\n",
    "x_test_svd = svd.transform(x_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.concatenate((x_train_svd, x_dev_svd, x_test_svd)))\n",
    "x_train_svd = scaler.transform(x_train_svd)\n",
    "x_dev_svd = scaler.transform(x_dev_svd)\n",
    "x_test_svd = scaler.transform(x_test_svd)\n",
    "\n",
    "clf = SVC(C = 0.1, probability = True)\n",
    "clf.fit(x_train_svd, y_train)\n",
    "\n",
    "svm_dev_pred = clf.predict_proba(x_dev_svd)[:, 1]\n",
    "svm_test_pred = clf.predict_proba(x_test_svd)[:, 1]\n",
    "\n",
    "train_labels['svm'] = (clf.predict_proba(x_train_svd)[:, 1] >= 0.5).astype(int)\n",
    "dev_labels['svm'] = (clf.predict_proba(x_dev_svd)[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "y_pred = (svm_dev_pred >= 0.5).astype(int)\n",
    "svm_precision = precision_score(y_dev, y_pred)\n",
    "svm_recall = recall_score(y_dev, y_pred)\n",
    "svm_f1 = f1_score(y_dev, y_pred)\n",
    "\n",
    "print(\"SVM Classifier...\")\n",
    "print(\"Precision score : \" + str(svm_precision))\n",
    "print(\"Recall score : \" + str(svm_recall))\n",
    "print(\"F1 score : \" + str(svm_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
